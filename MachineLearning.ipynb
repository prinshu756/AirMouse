{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMeibUkS0MgAjr39a6iDG3n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prinshu756/AirMouse/blob/main/MachineLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import pyautogui\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "#initialising mediapipe\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_draw = mp.solutions.drawing_utils\n",
        "hands = mp_hands.Hands(\n",
        "    max_num_hands=1,\n",
        "    min_detection_confidence=0.7,\n",
        "    min_tracking_confidence=0.7\n",
        ")\n",
        "\n",
        "screen_w, screen_h = pyautogui.size()\n",
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(3, 640)\n",
        "cap.set(4, 480)\n",
        "cap.set(cv2.CAP_PROP_BRIGHTNESS, 150)\n",
        "\n",
        "use_cuda = cv2.cuda.getCudaEnabledDeviceCount() > 0\n",
        "\n",
        "def fingers_up(hand):\n",
        "    tips = [4, 8, 12, 16, 20]\n",
        "    fingers = []\n",
        "\n",
        "    fingers.append(1 if hand.landmark[tips[0]].x < hand.landmark[tips[0] - 2].x else 0)\n",
        "\n",
        "    for id in range(1, 5):\n",
        "        fingers.append(1 if hand.landmark[tips[id]].y < hand.landmark[tips[id] - 2].y else 0)\n",
        "\n",
        "    return fingers\n",
        "\n",
        "prev_x, prev_y = 0, 0\n",
        "smooth_factor = 4\n",
        "prev_click_time = 0\n",
        "last_cursor_x, last_cursor_y = None, None\n",
        "\n",
        "scroll_threshold = 20\n",
        "last_scroll_time = 0\n",
        "scroll_cooldown = 0.2\n",
        "\n",
        "hand_active = False\n",
        "last_hand_seen_time = 0\n",
        "hand_timeout = 1.0\n",
        "\n",
        "if use_cuda:\n",
        "    gpu_frame = cv2.cuda_GpuMat()\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    if use_cuda:\n",
        "        gpu_frame.upload(img)\n",
        "        gpu_flipped = cv2.cuda.flip(gpu_frame, 1)     # GPU flip\n",
        "        gpu_rgb = cv2.cuda.cvtColor(gpu_flipped, cv2.COLOR_BGR2RGB)  # GPU BGRâ†’RGB\n",
        "        img_rgb = gpu_rgb.download()   # Download only once for mediapipe\n",
        "        img = gpu_flipped.download()\n",
        "    else:\n",
        "        img = cv2.flip(img, 1)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    h, w, _ = img.shape\n",
        "    result = hands.process(img_rgb)\n",
        "\n",
        "    if result.multi_hand_landmarks:\n",
        "        hand_active = True\n",
        "        last_hand_seen_time = time.time()\n",
        "\n",
        "        hand_landmarks = result.multi_hand_landmarks[0]\n",
        "        mp_draw.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
        "\n",
        "        fingers = fingers_up(hand_landmarks)\n",
        "        total_fingers = fingers.count(1)\n",
        "\n",
        "        index_tip = hand_landmarks.landmark[8]\n",
        "        x = int(index_tip.x * w)\n",
        "        y = int(index_tip.y * h)\n",
        "\n",
        "        norm_x = np.interp(x, [100, w - 100], [0, screen_w])\n",
        "        norm_y = np.interp(y, [100, h - 100], [0, screen_h])\n",
        "\n",
        "        curr_x = prev_x + (norm_x - prev_x) / smooth_factor\n",
        "        curr_y = prev_y + (norm_y - prev_y) / smooth_factor\n",
        "        prev_x, prev_y = curr_x, curr_y\n",
        "\n",
        "        if total_fingers == 1 and fingers[1] == 1:\n",
        "            pyautogui.moveTo(curr_x, curr_y, duration=0)\n",
        "            last_cursor_x, last_cursor_y = curr_x, curr_y\n",
        "\n",
        "        # Click\n",
        "        elif total_fingers == 5:\n",
        "            now = time.time()\n",
        "            if now - prev_click_time > 0.2:\n",
        "                pyautogui.click()\n",
        "                prev_click_time = now\n",
        "\n",
        "        # Scroll down\n",
        "        elif total_fingers == 3:\n",
        "            now = time.time()\n",
        "            if now - last_scroll_time > scroll_cooldown:\n",
        "                pyautogui.scroll(30)\n",
        "                last_scroll_time = now\n",
        "\n",
        "        # Scroll up\n",
        "        elif total_fingers == 2:\n",
        "            now = time.time()\n",
        "            if now - last_scroll_time > scroll_cooldown:\n",
        "                pyautogui.scroll(-30)\n",
        "                last_scroll_time = now\n",
        "\n",
        "    else:\n",
        "        if time.time() - last_hand_seen_time > hand_timeout:\n",
        "            hand_active = False\n",
        "\n",
        "        if hand_active and last_cursor_x is not None:\n",
        "            pyautogui.moveTo(last_cursor_x, last_cursor_y, duration=0)\n",
        "\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "Z2iWb8L-iqvC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}